This directory contains the experiments and case study used in our submission.

This experimenal setup has only been tested on Linux. 


=== Contents ===
Source files of four versions the tool PDAAAL, which is the subject of the case study
- PDAAAL-v1/  A recent development version of PDAAAL. The starting point of the case study
- PDAAAL-v2/  Like v1, but where bug 1 is fixed (intersection not taking into account epsilon-transitions in post*)
- PDAAAL-v3/  Like v2, but where bug 2 is fixed (swap of two lines in pre*)
- PDAAAL-v4/  Like v3, but where bug 3 is fixed (mismatch of assumption between parser and data structure)
The PDAAAL-v{1,2,3,4}/benchmark subfolder contains our code for running the experiments, 
while src/ contains the PDAAAL source, with bugfix modifications in versions {2,3,4}.

Precompiled binaries for each of the four versions.
- bin/generate-v{1,2,3,4}  Program to generate the random and exhaustive PDA and P-automata test cases. (version should not matter)
- bin/test-before-isabelle-v{1,2,3,4}  The program under test, reads in a test case, runs tool and generates Isabelle theory. (version matters)
- bin/delta-debug-v{1,2,3,4}  Program used as part of the delta-debug test case minimization. (version does not matter)

Test cases
- network-tests-json.tar.gz  Archive of test cases constructed from the network verification domain. 
- random-tests-json.tar.gz   Archive of randomly generated test cases. This can also generated by you (see below).
- exhaustive/  Folder contains the components of the exhaustive test. This can also be generated by you (see below).

Bash scripts (see more below)


=== Setup ===
Before running experiments, make sure to setup Isabelle as described in ../Formalization/README.txt
Also, if the path of your Isabelle installation is not '~/CAV2022/Isabelle2021-1/bin/isabelle', 
then please edit line 4 in both 'run-isabelle.sh' and 'delta-debug.sh' so that ISABELLE_PATH points
to your Isabelle installation.

Make sure the scripts and binaries are executable:
$ chmod +x *.sh bin/*


=== Build ===
(Optional)
The bin/ folder contains precompiled binaries. If you wish to build them yourself run:
$ ./build.sh


=== Generate/Extract Test Cases ===
For test cases from the networking domain extract the archive:
$ tar -xzf network-tests-json.tar.gz

(Options)
For random test cases either extract the archive:
$ tar -xzf random-tests-json.tar.gz
or 
generate test cases (specify random seed for -s, and number of test cases for -n):
$ mkdir -p random-tests-json
$ bin/generate-v1 --random -s 1 -d random-tests-json -n 15000
This takes a few minutes.

(Optional)
For exhaustive tests, you can re-generate the .json and .thy files in exhaustive/ folder using:
$ ./generate-exhaustive.sh

Note the file exhaustive/Test_Setup.thy is used as a common setup 
when running exhaustive tests with Isabelle. Don't delete it.


=== Running Tests ===
The 'run.sh' script provides a convenient way of running some or all experiments.
Since running all tests takes several hundred CPU-days (we ran the experiments on a compute cluster), 
we provide also, for each of the three types of test, a small and a large subset of experiments to run.
The options are 'run.sh {network,random,exhaustive} {small,large,all} {1,2,3,4}'

For example, to run the small subset of network experiments on the original version of the tool:
$ ./run.sh network small 1
This takes a few minutes, and will not show any failing cases.

To run the large subset of the random experiments on the original version of the tool:
$ ./run.sh random large 1
This takes around 2 hours, and will show some (~84) failed cases - as 'Unfinished session(s)' in the Isabelle log file.

To run again the large subset of the random experiments on the version, where the first bug is fixed:
$ ./run.sh random large 2
This shows (for the provided test cases) that only case 9847 fails. (The large subset was chosen to include this case.)

To run the small subset of the exhaustive tests on the tool version, where bugs 1 and 2 are fixed, do: 
$ ./run.sh exhaustive small 3
This takes 5-10 minutes time, but finds no bugs (in the small subset).

If your computer had nothing else to do for a year, you could verify that all exhaustive test cases pass in the last version:
$ ./run.sh exhaustive all 4
WARNING: This takes several months to a year on a standard computer. 

You can also run specific test cases. For instance, to run version 2 on the random test cases 42, 43 and 44:
$ ./run-tool.sh random-tests-json 2 42 44 --state-names
$ ./run-isabelle.sh random-tests-2-thy 42 44
(The parameter --state-names is needed for random tests, but not for network tests, due to different structures in their input format.)


=== Test Case Minimization with Delta Debugging ===
The script 'delta-debug.sh' allow minimizing a failing test case using the delta debugging technique.
To run the example in the paper (assuming that you did not modify the random test cases):
$ ./delta-debug.sh random-tests-json 2 9847
This takes 15-30 minutes, and prints the minimal test case in the terminal in a JSON format.

